# Audio, MIDI y pages

En esta sesión empezaremos a hablar de audio en el navegador. De manera paralela continuaremos con el tema de despliegue de páginas en Github Pages. 

## Antecedentes y plataformas relevantes

Aproximación personal en orden más o menos cronológico al audio en el navegador: 

- Antes del navegador: [SuperCollider](https://supercollider.github.io/) y [Tidal-Cycles](https://tidalcycles.org/). También relevante mencionar el caso de [dirt](https://codeberg.org/uzu/dirt) y [superdirt](https://github.com/musikinformatik/SuperDirt).  

- [Estuary](https://estuary.mcmaster.ca/) > [repositorio](https://github.com/dktr0/estuary). En específico rescato dos proyectos: mini-tidal y sei8s. 

- [Seis8s](https://seis8s.org/) y la música latina. [Documentación](https://seis8s.org/docs). 

- Hoy en día es posible encontrar plataformas sofisticadas para hacer live coding con audio en el navegador: [Strudel](https://strudel.cc/) y [Mercury](https://mercury-playground.pages.dev/). 

- Nota interesante: la mayoría de estos entornos ya están construídos como aplicaciones que integran un editor de texto, una sintaxis y un motor de audio. Algunas de ellas, como Strudel, permiten usar los entornos como bibliotecas. Revisaremos esto al finalizar la sesión. 

## Introducción 

Hay tres temas audio que podemos abordar para los proyectos que vamos a contruir en este curso: 

- Reproducción de muestras. Tal vez es la aproximación más común y más usada. Tenemos un archivo de audio que podemos reproducir a partir de un evento.

- Síntesis de audio. Esta aproximación podría no ser tan común pero puede ser útil en contextos donde no utilizamos archivos de audio. 

- Análisis de audio. Podemos obtener información de las muestras que estamos reproduciendo o de los síntetizadores que estamos manipulando. Podemos usar esta información para algo, tal vez el resultado más común es dibujar una forma de onda. Nota: Análisis de audio y análisis de imagen nos permiten hacer correlaciones entre estas dos dimensiones, aquí está un posible puente de integración entre audio y sonido. 

Podemos encontrar muchos recursos para explorar esta distinción, conceptual, técnica y e históricamente. Uno de los recursos que me parecen más integrados es el [Tutorial de Sonido de Processing](https://processing.org/tutorials/sound). 

## Actividad 1

Una página web que integre: reproducción de muestras, síntesis y análisis de audio. Para resolver esta actividad de manera sencilla podemos utilizar Tone.js. 

- Primera característica: uso de 4 muestras de sonido que puedan ejecutarse con las teclas 1, 2, 3, y 4 del teclado. 

- Segunda característica: las teclas Q, W, E, R, T, Y y U asocidadas a escala de Do Mayor generada con Tone.js. 

- Tercera característica: incorporar un analizador de audio que tome ambas señales, muestra y síntesis y que permita arrojar información que dibuje una forma de onda. 

- Característica extra: Leer los valores de un controlador [MIDI](https://es.wikipedia.org/wiki/MIDI) y mapearlos a las 4 muestras y a la escala del sintetizador. 

Si pensamos estas librerías como capas de abstracción, podemos descender de nivel: Hacer esto mismo pero con WebAudioAPI. 

Recomendaciones con archivos de audio. 

## Actividad 2

Subir este proyecto a Github Pages. Esto supone un repaso de lo que vimos la semana pasada. 

## Actividad 3

Si da tiempo: hacer una prueba con [@strudel/web](https://codeberg.org/uzu/strudel/src/branch/main/packages/web) en una página. 